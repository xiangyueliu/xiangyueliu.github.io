<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Xiangyue Liu, Liu Xiangyue, Emma Liu, Beihang University, HKUST"> 
<meta name="description" content="Homepage of Xiangyue Liu">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Xiangyue Liu@HKUST</title>
<style>
    .smaller-image {
      width: 20%;
    }
</style>


</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/Lxiangyue" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Xiangyue Liu </h1>
					<h1></h1>
					<h1></h1>
					</div>
				<h3>PhD Candidate</h3>
				<p>
					Hong Kong University of Science and Technology <br>
					Clear Water Bay, Kowloon, HongKong.<br>
					<br>
					Email: xliufz [at] connect [dot] ust [dot] hk<br>
					
				</p>
				<p> 
					<a href="https://scholar.google.com/citations?user=m3c3jnYAAAAJ&hl=en"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/Lxiangyue"><img src="./pic/github.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.xiaohongshu.com/user/profile/5c55949e000000001a01a65b?xhsshare=CopyLink&appuid=5c55949e000000001a01a65b&apptime=1729960245&share_id=4478bd34bec34d0eb824cb592fd978c2"><img src="./pic/xiaohongshu.png" height="30px" style="margin-bottom:-3px"></a>
				</p>
			</td>
			<td>
				<img src="./pic/Xiangyue.jpg" border="0" width="240"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
	I'm a second-year PhD candidate of ECE at <a href="https://hkust.edu.hk/zh-hans">The Hong Kong University of Science and Technology (HKUST)</a>, under the supervision of <a href="https://ece.hkust.edu.hk/pingtan">Prof. Ping Tan</a>. 
	I was a visiting student (RA) at <a href="https://iiis.tsinghua.edu.cn/en/">Tsinghua University</a> advised by <a href="https://ericyi.github.io/">Prof. Li Yi</a> and <a href="http://people.iiis.tsinghua.edu.cn/~gaoyang/">Prof. Yang Gao</a>. 
	I obtained my M.S. in Software Engineering from <a href="https://ev.buaa.edu.cn/"> Beihang University </a>, and B.Eng in Software Engineering from <a href="https://en.nenu.edu.cn/">Northeast Normal University</a>. 
	I am a member of <a href="https://anysyn3d.github.io/about.html">AnySyn3D</a>.
<p>
	My research interests lie in <b>Computer Vision</b> and <b>Robotics</b>. 
	I currently work on Embodied AI, 3D/4D reconstruction, generation, and editing. Early interests include visual SLAM and MVS. 
<p><i style="color: red; display: inline;">Feel free to contact me by email if you are interested in discussing or collaborating with me.</i></p>


<h2>News</h2>
<div style="height: 240px; overflow: auto;">
<ul>
	<li>
		[11/2024] One paper was accepted by <a href="https://3dvconf.github.io/2025/"> 3DV 2025 </a>.
	</li>
	<li>
		[02/2024] One paper was accepted by <a href="https://cvpr.thecvf.com/Conferences/2024"> CVPR 2024 </a>.
	</li>
	<li>
		[09/2023] I start pursuing my Ph.D. degree at <a href="https://hkust.edu.hk/zh-hans"> HKUST </a>.
	</li>
	<li>
		[06/2022] Two paper were accepted by <a href="https://eccv2022.ecva.net/"> ECCV 2022 </a>.
	</li>
	<li>
		[02/2022] One paper was accepted by <a href="https://cvpr2022.thecvf.com/"> CVPR 2022 </a>.
	</li>
	<li>
		[06/2021] Graduated from <a href="https://www.bnu.edu.cn/"> Beihang University </a>.
	</li>
	<li>
		[01/2021] One paper was accepted by <a href="https://cvpr2022.thecvf.com/"> ICRA 2021 </a>.
	</li>
</ul>
</div>

<h2>Internship</h2>
<table id="tbPublications" width="100%">
	<tbody>
	<p></p>
	</td>
	<tr>
		<td width="306">
		<img src="./internship/tencent.png" width="200x" style="box-shadow: 4px 4px 8px #ffffff">
		</td>
		<td>
		<p><b> Tencent AI Lab </b></p>
		<p>Sept. 2023 - Dec. 2024, Tencent AI Lab, Gemdale Viseen Tower, ShenZhen, China </p>
		<p>worked with <a href="https://qzhang-cv.github.io/">Dr. Qi Zhang</a>, <a href="https://scholar.google.com/citations?user=DTIh8o4AAAAJ&hl=en">Yuxin Wen</a></p>
		<em>Topic: Digital Avatar, Talking Head</em>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
		<tr>
		<td width="306">
		<img src="./internship/Unitree.png" width="200x" style="box-shadow: 4px 4px 8px #ffffff">
		</td>
		<td>
		<p><b> Unitree </b></p>
		<p>Apr. 2024 - Aug. 2024, Unitree, R&D departments, Hangzhou, China </p>
		<p>closely worked with <a href="https://wyhuai.github.io/info/" target="_blank">Yinhuai Wang</a></p>
		<em>Topic: Real World Humanoid-Object Interaction</em>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./internship/Microsoft-logo.png" width="255px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b> Microsoft Research Asia </b></p>
		<p>Apr. 2023 - Mar. 2024, Beijing, China </p>
		<p>closely worked with <a href="https://www.microsoft.com/en-us/research/people/tianyuhe/" target="_blank">Tianyu He</a> and <a href="https://tan-xu.github.io/" target="_blank">Xu Tan</a> </p>
		<em>Topic: Talking Head Generation</em>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
</tbody></table>

<h2>Education</h2>
<table id="tbPublications" width="100%">
	<tbody>
	<tr>
		<td width="306">
		<img src="./education/hkust.png" width="270px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
			<p><b>The Hong Kong University of Science and Technology, Hong Kong</b></p>
			<p>PhD Student in Visual Intelligence Lab, HKUST </p>
			<p>Advisor: <a href="https://cqf.io/">Prof. Qifeng Chen</a> </p>
			<p>Sep. 2024 - Future</p>
		</td>
	</tr>

	<!--########################-->
	<p></p>
	<p></p>
	<p></p>
	<tr>
		<td width="306">
			<img src="./education/pku.png" width="230px" style="box-shadow: 4px 4px 8px #ffffff" >	
			</td>
			<td>
			<p><b>Peking University, China</b></p>
			<p>Master of Science in Computer Science </p>
			<p>Advisor: Prof. Jie Chen </p>
			<p>Sep. 2021 - Jun. 2024 </p>
		</td>
	</tr>

	<!--########################-->
	<p></p>
	<p></p>
	<p></p>
	<tr>
		<td width="306">
			<img src="./education/bnu.png" width="250px" style="box-shadow: 4px 4px 8px #ffffff">
			</td>				
			<td>
			<p><b>Beijing Normal Univesity, China</b></p>
			<p>Bachelor of Management in Information Systems </p>
			<p>Sep. 2017 - Jun. 2021 <p>
		</td>
	</tr>
</tbody></table>


<h2> Selected Publications </h2>
<table id="tbPublications" width="100%">
	<tbody>
		<td><b>/*Preprints*/</b>
			<p></p>
		</td>
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2024_SkillMimic.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b> SkillMimic: Learning Reusable Basketball Skills from Demonstrations </b></p>
			<p> Yinhuai Wang*, Qihan Zhao*, <b>Runyi Yu*</b>, Ailing Zeng, Jing Lin, Zhengyi Luo, Hok Wai Tsui, Jiwen Yu, Xiu Li, Qifeng Chen, Jian Zhang, Lei Zhang, Ping Tan</p>
			<p> [<a href="https://arxiv.org/abs/2406.08096">paper</a>] [<a href="https://ingrid789.github.io/SkillMimic/">project page</a>] [<a href="https://github.com/wyhuai/SkillMimic">code</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2024_MyTalk.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>Make Your Actor Talk: Generalizable and High-Fidelity Lip Sync with Motion and Appearance Disentanglement </b></p>
			<p> <b>Runyi Yu</b>, Tianyu He, Ailing Zhang, Yuchi Wang, Junliang Guo, Xu Tan, Chang Liu, Jie Chen, Jiang Bian </p>
			<p> [<a href="https://arxiv.org/abs/2406.08096">paper</a>] [<a href="https://ingrid789.github.io/MyTalk/">project page</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	
		<!-- ------------------------ -->
		<td><b>/*Conference*/</b>
		<p></p>
		</td>
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2024_Instruct.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation </b></p>
			<em>ECCV 2024</em>
			<p> Yuchi Wang, Junliang Guo, Jianhong Bai, <b>Runyi Yu</b>, Tianyu He, Xu Tan, Xu Sun, Jiang Bian </p>
			<p> [<a href="https://arxiv.org/abs/2405.15758">paper</a>] [<a href="https://wangyuchi369.github.io/InstructAvatar/">project page</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<!--########################-->
		<!-- <tr>
			<td width="306">
			<img src="./pub/2024_GuideMotion.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>Local Action-Guided Motion Diffusion Model for Text-to-Motion Generation</b></p>
			<p> Peng Jin, Hao Li, Zesen Cheng, Kehan Li, <b>Runyi Yu</b>, Chang Liu, Xiangyang Ji, Li Yuan, Jie Chen</p>
			<em>ECCV 2024</em>
			<p> [<a href="https://arxiv.org/abs/2407.10528">paper</a>] [<a href="https://jpthu17.github.io/GuidedMotion-project/">project page</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr> -->

		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2024_GAIA.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>GAIA: Data-driven Zero-shot Talking Avatar Generation</b></p>
			<p> Tianyu He*, Junliang Guo*, <b>Runyi Yu*</b>, Yuchi Wang*, Jialiang Zhu, Kaikai An, Leyi Li, Xu Tan, Chunyu Wang, Han Hu, HsiangTao Wu, Sheng Zhao, Jiang Bian </p>
			<em>ICLR 2024</em>
			<p> [<a href="https://arxiv.org/abs/2311.15230">paper</a>] [<a href="https://gaiavatar.github.io/gaia/">project page</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2023_LaPE.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>LaPE: Layer-adaptive Position Embedding for Vision Transformers with Independent Layer Normalization</b></p>
			<p> <b>Runyi Yu*</b>, Zhennan Wang*, Yinhuai Wang*, Kehan Li, Chang Liu, Haoyi Duan, Xiangyang Ji, Jie Chen </p>
			<em>ICCV 2023</em>
			<p> [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.pdf">paper</a>] [<a href="https://github.com/Ingrid725/LaPE">code</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2023_ACSeg.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation</b></p>
			<p> Kehan Li, Zhennan Wang, Zesen Cheng, <b>Runyi Yu</b>, Yian Zhao, Guoli Song, Chang Liu, Li Yuan, Jie Chen </p>
			<em>CVPR 2023 <i style="color: red; display: inline;">Hightlight</i></em>
			<p> [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_ACSeg_Adaptive_Conceptualization_for_Unsupervised_Semantic_Segmentation_CVPR_2023_paper.pdf">paper</a>] [<a href="https://lkhl.github.io/ACSeg/">project page</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2023_Unlimited.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>Unlimited-Size Diffusion Restoration</b></p>
			<p> Yinhuai Wang, Jiwen Yu, <b>Runyi Yu</b>, Jian Zhang </p>
			<em>CVPR Workshop 2023 <i style="color: red; display: inline;">Oral</i></em>
			<p> [<a href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Wang_Unlimited-Size_Diffusion_Restoration_CVPRW_2023_paper.pdf">paper</a>] [<a href="https://github.com/wyhuai/DDNM/tree/main/hq_demo">code</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/2022_Locality.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>Locality guidance for improving vision transformers on tiny datasets</b></p>
			<p> Kehan Li*, <b>Runyi Yu*</b>, Zhennan Wang, Li Yuan, Guoli Song, Jie Chen</p>
			<em>ECCV 2022</em>
			<p> [<a href="https://arxiv.org/pdf/2207.10026">paper</a>] [<a href="https://github.com/lkhl/tiny-transformers">code</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	</tbody>
</table>

<h2>Community Services</h2>
<ul>
	<li>	
	<b>Student Reviewers:</b><br>
	The 34rd International Joint Conference on Artificial Intelligence (IJCAI 2025)<br>
	The 33rd International Joint Conference on Artificial Intelligence (IJCAI 2024)<br>
	IEEE Transactions on Multimedia (TMM)<br>
	</li>
</ul>

<div id="footer">
	<div id="footer-text"></div>
</div>

<br>
<br>
<!-- <div style="width: 50%; height: auto; margin: auto;"> -->
<div>
	<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=6c7172&w=300&t=tt&d=fEfi1TeABOpJh2PR30Va7JSXWyub5nA4b3oo2lrqrrE&co=f4f4f4&ct=7c4c4c'></script>
</div>
<p><center> &copy; Xiangyue Liu </center></p>


</div>
</body></html>
