<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="icon" type="image/jpg" href="./pic/IMG_icon.jpg">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Xiangyue Liu, Liu Xiangyue, Emma Liu, Beihang University, HKUST"> 
<meta name="description" content="Homepage of Xiangyue Liu">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Xiangyue Liu</title>
<style>
    .smaller-image {
      width: 20%;
    }
</style>


</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/Lxiangyue" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>


<table>
    <tbody>
        <tr>
            <td style="vertical-align: top; width: 220px;">
                <!-- <img src="./pic/IMG_8133.jpg" border="0" width="220"><br> -->
                <img src="./pic/IMG_8157.jpg" border="0" width="220"><br>
                <!-- <img src="./pic/IMG_5935.jpg" border="0" width="220"><br> -->
            </td>
            <td style="vertical-align: bottom; padding-left: 40px;"> 
                <div id="toptitle">					
                    <h1>Xiangyue Liu</h1>
                    <h3>PhD Candidate</h3>
                    <p>
                        Hong Kong University of Science and Technology <br>
                        <br>
						Von Neumann Institute<br>
						Department of ECE<br>
                        Email: xliufz [at] connect [dot] ust [dot] hk<br>
                    </p>
                    <p> 
                        <a href="https://scholar.google.com/citations?user=m3c3jnYAAAAJ&hl=en" style="margin-right: 2px;">
                            <img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px">
                        </a>
                        <a href="https://github.com/Lxiangyue">
                            <img src="./pic/github.jpg" height="30px" style="margin-bottom:-3px">
                        </a>
                        <a href="https://www.linkedin.com/in/xiangyue-liu-45589934b">
                            <img src="./pic/LinkedIn.jpg" height="30px" style="margin-bottom:-3px">
                        </a>
                        <!-- <a href="https://www.xiaohongshu.com/user/profile/5c55949e000000001a01a65b?xhsshare=CopyLink&appuid=5c55949e000000001a01a65b&apptime=1729960245&share_id=4478bd34bec34d0eb824cb592fd978c2">
                            <img src="./pic/xiaohongshu.png" height="30px" style="margin-bottom:-3px">
                        </a> -->
                    </p>
                </div>
            </td>
        </tr>
    </tbody>
</table>

<h2>Biography</h2>
<p>
	I'm a third-year PhD candidate of ECE at <a href="https://hkust.edu.hk/zh-hans">Hong Kong University of Science and Technology (HKUST)</a>, under the supervision of <a href="https://ece.hkust.edu.hk/pingtan">Prof. Ping Tan</a>. 
	I was an RA at <a href="https://iiis.tsinghua.edu.cn/en/">Tsinghua University</a> advised by <a href="https://ericyi.github.io/">Prof. Li Yi</a> and <a href="http://people.iiis.tsinghua.edu.cn/~gaoyang/">Prof. Yang Gao</a>. 
	I obtained my M.S. from <a href="https://ev.buaa.edu.cn/"> Beihang University</a>, and B.Eng from <a href="https://en.nenu.edu.cn/">Northeast Normal University</a>. 
    <!-- I am a member of <a href="https://anysyn3d.github.io/about.html">AnySyn3D</a>. -->
<p>
	My research interests are broadly in computer vision, with a focus on text-to-image generation (T2I), unified understanding and generation models, multimodal large language models (MLLM), AI-generated content (AIGC), etc.

<h2>News</h2>
<div style=overflow: auto;">
<ul>
	<li style="line-height: 1.5;"> 
		[10/2025] We organized <a href="https://www.iros25.org/">IROS 2025</a> workshop on <a href="https://4drobotics-iros2025.github.io/">Advancements for Intelligent Robotics in 4D Scenes</a>. 
	</li>
	<li>
		[11/2024] One paper accepted to <a href="https://3dvconf.github.io/2025/">3DV 2025</a>.
	</li>
	<li>
		[02/2024] One paper accepted to <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a>.
	</li>
	<li>
		[09/2023] I started pursuing my Ph.D. degree at <a href="https://hkust.edu.hk/zh-hans">HKUST</a>.
	</li>
</ul>
</div>
	
<h2> Selected Publications </h2>
<!-- <h2> Publications </h2> -->
<small>*: equal contribution</small>
<table id="tbPublications" width="100%">
	<tbody>
		<tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
 		<tr>
			<td width="306">
			<img src="./pub/Plan-and-Paint.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>Plan-and-Paint: Collaborating Semantic and Noise Reasoning for Text-to-Image Generation</b></p>
			<p><b>Xiangyue Liu</b>, Ping Tan</p>
			<p> [<a href="https://openreview.net/pdf?id=DC0AtnJXeQ">preprint</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>     
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>       
		<!--########################-->
		<tr>
			<td width="306">
			<img src="./pub/NoiseAR.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>NoiseAR: AutoRegressing Initial Noise Prior for Diffusion Models</b></p>
			<p>Zeming Li*, <b>Xiangyue Liu*</b>, Xiangyu Zhang, Ping Tan, Heung-Yeung Shum</p>
			<p> [<a href="https://arxiv.org/abs/2506.01337">arxiv</a>] [<a href="https://github.com/HKUST-SAIL/NoiseAR/">code</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<!--########################-->
		<tr>
			<td width="306">
			<video width="285" muted autoplay loop>
			    <source src="./pub/3DV_GSEditor.mp4" type="video/mp4">
			</video>
			</td>
			<td>
			<p><b>GaussianAvatar-Editor: Photorealistic Animatable Gaussian Head Avatar Editor</b></p>
			<p> <b>Xiangyue Liu</b>, Kunming Luo, Heng Li, Qi Zhang, Yuan Liu, Li Yi, Ping Tan </p>
			<em>3DV 2025</em> <span style="color: red;">(no rebuttal)</span>
			<p>[<a href="https://arxiv.org/abs/2501.09978">paper</a>] [<a href="https://xiangyueliu.github.io/GaussianAvatar-Editor/">project</a>] [<a href="https://github.com/Lxiangyue/GaussianAvatar-Editor">code</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<!--########################-->
		<tr>
			<td width="306">
			<video width="285" muted autoplay loop>
			    <source src="./pub/CVPR_GenN2N.mp4" type="video/mp4">
			</video>
			</td>
			<td>
			<p><b>GenN2N: Generative NeRF2NeRF Translation</b></p>
			<p> <b>Xiangyue Liu</b>, Han Xue, Kunming Luo, Ping Tan, Li Yi </p>
			<em>CVPR 2024</em> <span style="color: red;">(score 554)</span>
			<p> [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_GenN2N_Generative_NeRF2NeRF_Translation_CVPR_2024_paper.pdf">paper</a>] [<a href="https://xiangyueliu.github.io/GenN2N/">project</a>] [<a href="https://mp.weixin.qq.com/s/9CYkP_-oV6g4H5Pcs9PAgw">report</a>] [<a href="https://github.com/Lxiangyue/GenN2N">code</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

		
		<!-- <tr>
			<td width="306">
			<video width="285" muted autoplay loop>
			    <source src="./pub/Uni3D.mp4" type="video/mp4">
			</video>
			</td>
			<td>
			<p><b>Uni3D: Single Video-based Dynamic 3D Modeling for Humans and Animals with a Unified Template</b></p>
			<p> <b>Xiangyue Liu</b>, Weixin Xu, Shuchang Zhou, Li Yi, Yang Gao </p>
			<em>Under Review</em>
			<p> [<a href="https://xiangyueliu.github.io/Uni3D/">project</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr> -->

		<!--########################-->
		<!-- <tr>
			<td width="306">
			<img src="./pub/ECCV_Sob.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>Sobolev Training for Implicit Neural Representations with Approximated Image Derivatives</b></p>
			<p> Wentao Yuan, Qingtian Zhu, <b>Xiangyue Liu</b>, Yikang Ding, Haotian Zhang, Chi Zhang </p>
			<em>ECCV 2022</em>
			<p> [<a href="https://arxiv.org/abs/2207.10395?context=cs">paper</a>] [<a href="https://github.com/megvii-research/Sobolev_INRs">code</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr> -->
		
		<!--########################-->
		<!-- <tr>
			<td width="306">
			<img src="./pub/ECCV_KDMVS.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>KD-MVS: Knowledge Distillation Based Self-supervised Learning for Multi-view Stereo</b></p>
			<p> Yikang Ding, Qingtian Zhu, <b>Xiangyue Liu</b>, Wentao Yuan, Haotian Zhang, Chi Zhang </p>
			<em>ECCV 2022</em>
			<p> [<a href="https://arxiv.org/abs/2207.10425">paper</a>] [<a href="https://github.com/megvii-research/KD-MVS">code</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr> -->
		
		<!--########################-->
		<!-- <tr>
			<td width="306">
			<img src="./pub/CVPR_TransMVSNet.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>TransMVSNet: Global Context-aware Multi-view Stereo Network with Transformers</b></p>
			<p> Yikang Ding*, Wentao Yuan*, Qingtian Zhu, Haotian Zhang, <b>Xiangyue Liu</b>, Yuanjiang Wang, Xiao Liu </p>
			<em>CVPR 2022</em>
			<p> [<a href="https://arxiv.org/abs/2111.14600">paper</a>] [<a href="https://dingyikang.github.io/transmvsnet.github.io/">project</a>] [<a href="https://github.com/MegviiRobot/TransMVSNet">code</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr> -->
		
		<!--########################-->
		<!-- <tr>
			<td width="306">
			<img src="./pub/ICRA_RPR.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>Structure Reconstruction Using Ray-Point-Ray Features: Representation and Camera Pose Estimation</b></p>
			<p> Yijia He*, <b>Xiangyue Liu*</b>, Xiao Liu, Ji Zhao </p>
			<em>ICRA 2021</em>
			<p> [<a href="https://ieeexplore.ieee.org/document/9561283">paper</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr> -->

		<!--########################-->
<!-- 		<tr>
			<td width="306">
			<img src="./pub/IJCAI_3DSeg.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>
			<td>
			<p><b>2nd Place Solution to Instance Segmentation of IJCAI 3D AI Challenge 2020</b></p>
			<p> Kai Jiang*, <b>Xiangyue Liu*</b>, Zhang Ju*, Xiang Luo </p>
			<em>IJCAI Workshop 2020</em>
			<p> [<a href="https://arxiv.org/abs/2010.10957">paper</a>]
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>		 -->
		
	</tbody>
</table>

	
<h2>Research Interns</h2>
<table id="tbPublications" width="100%">
	<tbody>
	<p></p>
	</td>

    <!-- <tr>
        <td width="306" align="left" style="vertical-align: middle; padding-bottom: 30px;">
            <img src="./internship/tencent_hunyuan.jpg" width="200px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">
        </td>
        <td style="vertical-align: middle; padding-bottom: 30px;">
            <p style="font-size: 1.1em;"><b>Tencent Hunyuan Foundation Model Team</b></p>
            
            <p style="margin-bottom: 4px;"><em>Topic: Architecture Design & Multi-modal Pretraining</em></p>
            <!-- <p style="color: #444;"> -->
            <p style="font-size: 0.9em; color: #666;">Nov. 2025 - Present. Mentors: <a href="https://scholar.google.com/citations?user=TZ0nnhgAAAAJ&hl=zh-CN">Dr. Zijian Zhang</a> and Dr. Miles Yang</p>
            </p>
		</td>
    </tr> -->
	

    <tr>
        <td width="306" align="left" style="vertical-align: middle; padding-bottom: 30px;">
            <img src="./internship/tencent.png" width="200px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">
        </td>
        <td style="vertical-align: middle; padding-bottom: 30px;">
            <p style="font-size: 1.1em;"><b>Tencent AI Lab</b></p>
            <p style="margin-bottom: 4px;"><em>Topic: Digital Avatar</em></p>
            <p style="font-size: 0.9em; color: #666;">Sept. 2023 - Dec. 2024. Mentors: <a href="https://scholar.google.com/citations?user=DTIh8o4AAAAJ&hl=en">Dr. Yuxin Wen</a> and <a href="https://qzhang-cv.github.io/">Dr. Qi Zhang</a></p>
        	</p>
		</td>
    </tr>

    <tr>
        <td width="306" align="left" style="vertical-align: top; padding-top: 10px;">
            <img src="./internship/megvii.png" width="200px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">
        </td>
        <td style="vertical-align: top;">
            <p style="font-size: 1.1em; margin-bottom: 15px;"><b>Megvii Research</b></p>
            
            <div style="margin-bottom: 20px;">
                <p style="margin-bottom: 4px;"><em>Topic: NeRF, Monocular Video Reconstruction</em></p>
                <p style="font-size: 0.9em; color: #666;">Apr. 2022 - Aug. 2023, AIC. Mentors: <a href="https://scholar.google.com/citations?user=DWb7N7IAAAAJ&hl=en">Weixin Xu</a>, <a href="https://scholar.google.com/citations?user=5u95wzMAAAAJ&hl=en">Yi Yang</a>, and <a href="https://zsc.github.io/">Dr. Shuchang Zhou</a></p>
                </p>
            </div>

            <div style="margin-bottom: 20px;">
                <p style="margin-bottom: 4px;"><em>Topic: Deep MVS</em></p>
                <p style="font-size: 0.9em; color: #666;">Jul. 2021 - Apr. 2022, 3D Vision. Mentors: <a href="https://scholar.google.com/citations?user=X1Sa_GYAAAAJ&hl=zh-CN/">Haotian Zhang</a> and <a href="http://www.liuxiao.org/">Xiao Liu</a></p>
                </p>
            </div>

            <div>
                <p style="margin-bottom: 4px;"><em>Topic: Visual SLAM</em></p>
                <p style="font-size: 0.9em; color: #666;">Aug. 2019 - Apr. 2020, SLAM & AR. Mentors: <a href="https://scholar.google.com/citations?hl=en&user=_0lKGnkAAAAJ&view_op=list_works&sortby=pubdate">Dr. Yijia He</a> and <a href="http://www.liuxiao.org/">Xiao Liu</a></p>
                </p>
            </div>
			
        </td>
    </tr>
	
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
</tbody></table>



<h2>Education & Visiting</h2>
<table id="tbPublications" width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
	<tbody>
		
	<p></p>
	</td>
		
	<tr>
		<td width="306" align="left" style="vertical-align: middle; padding-bottom: 30px;">
			<img src="./education/hkust.png" width="260px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">
		</td>				
		<td style="vertical-align: middle; padding-bottom: 30px;">
			<p style="font-size: 1.1em;"><b>The Hong Kong University of Science and Technology</b></p>
			<p>Ph.D. Candidate in ECE</p> 
			<p style="font-size: 0.9em; color: #666;">Sep. 2023 - Future. Advisor: <a href="https://ece.hkust.edu.hk/pingtan">Prof. Ping Tan</a></p>
		</td>
	</tr>

	<tr>
		<td width="306" align="left" style="vertical-align: middle; padding-bottom: 30px;">
			<img src="./education/thu.png" width="230px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">	
		</td>
		<td style="vertical-align: middle; padding-bottom: 30px;">
			<p style="font-size: 1.1em;"><b>Tsinghua University</b></p>
			<p>Research Assistant in IIIS</p>
			<p style="font-size: 0.9em; color: #666;">Aug. 2021 - Aug. 2023. Advisors: <a href="https://ericyi.github.io/">Prof. Li Yi</a> and <a href="http://people.iiis.tsinghua.edu.cn/~gaoyang/">Prof. Yang Gao</a></p>
		</td>
	</tr>

	<tr>
		<td width="306" align="left" style="vertical-align: middle; padding-bottom: 30px;">
			<img src="./education/buaa.png" width="230px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">	
		</td>
		<td style="vertical-align: middle; padding-bottom: 30px;">
			<p style="font-size: 1.1em;"><b>Beihang University</b></p>
			<p>M.Sc. in Software Engineering</p> 
			<p style="font-size: 0.9em; color: #666;">Sep. 2018 - Jun. 2021</p>
		</td>
	</tr>
		
	<tr>
		<td width="306" align="left" style="vertical-align: middle; padding-bottom: 30px;">
			<img src="./education/nenu.png" width="230px" style="box-shadow: 4px 4px 8px #dcdcdc; border-radius: 8px;">
		</td>				
		<td style="vertical-align: middle; padding-bottom: 30px;">
			<p style="font-size: 1.1em;"><b>Northeast Normal University</b></p>
			<p>B.E. in Software Engineering</p>
			<p style="font-size: 0.9em; color: #666;">Sep. 2014 - Jun. 2018</p>
		</td>
	</tr>
</tbody>
</table>
	



<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	<tbody>
	<tr><td> [06/2021] Outstanding Graduate Student of Beijing.</td></tr>
	<tr><td> [08/2020] Top 0.3% in 3D Instance Segmentation Challenge at IJCAI 2020. (Rank 2 out of 559)</td></tr>
	<tr><td> [10/2016] National College Students Innovation and Entrepreneurship Training Program.</td></tr>
	</tbody>
</table>

	
<h2>Teaching Assistant</h2>
<table id="tbTeaching" border="0" width="100%">
	<body>
		<tr><td> 2025-2026</td><td>Spring</td><td>Electronic and Information Technology (HKUST, ELEC1010)</td></tr>
		<tr><td> 2024-2025</td><td>Fall</td><td>Computer Communication Networks (HKUST, ELEC3120)</td></tr>	
		<tr><td> 2023-2024</td><td>Spring</td><td>Electronic and Information Technology (HKUST, ELEC1010)</td></tr>
	</tbody>
</table>


<h2>Community Services</h2>
<table style="border-spacing:2px">
	<tbody>
	<tr><td> Workshop Organizer: IROS</td></tr>
	<tr><td> Journal Reviewer: TPAMI</td></tr>
	<tr><td> Conference Reviewer: ICCV, ECCV, ICRA, 3DV, ICLR</td></tr>
	</tbody>
</table>
	
	
<!-- <div id="footer">
	<div id="footer-text"></div>
</div> -->

	
<br>
<br>
<div>
	<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=6c7172&w=300&t=tt&d=fEfi1TeABOpJh2PR30Va7JSXWyub5nA4b3oo2lrqrrE&co=f4f4f4&ct=7c4c4c'></script>
</div>
<p><center> &copy; Xiangyue Liu </center></p>


</div>
</body></html>





















































































































































